{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from AudioOnsetUtils import *\n",
    "\n",
    "RAW_EOG_CHANNELS = [u'EXG1', u'EXG2', u'EXG3', u'EXG4']\n",
    "MASTOID_CHANNELS = [u'EXG5', u'EXG6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell gets filtered data so we can open ICA for Participant PNUM\n",
    "\n",
    "def get_participant_filtered_data(PNUM):\n",
    "    data_raw_file = os.path.join('raw_data', 'P' + PNUM + '-raw.fif')\n",
    "    raw = mne.io.read_raw_fif(data_raw_file)\n",
    "\n",
    "    # remove mastoid channels if present \n",
    "    if MASTOID_CHANNELS[0] in raw.ch_names:\n",
    "        mne.io.set_eeg_reference(raw.load_data(), MASTOID_CHANNELS, copy=False) # inplace\n",
    "        raw.drop_channels(MASTOID_CHANNELS)\n",
    "\n",
    "    # Drop bad channels - in place on raw\n",
    "    for bad_channel in raw.info['bads']:\n",
    "        raw.drop_channels(bad_channel)\n",
    "        print(\"dropped: \" + bad_channel)\n",
    "\n",
    "    eeg_picks = mne.pick_types(raw.info, meg=False, eeg=True, eog=False, stim=False, exclude=[])\n",
    "\n",
    "    # bandpass filter - keeping a frequency range between 0.5 (high pass filter) and 30 Hz (low pass filter)\n",
    "    filtered_data = raw.load_data().filter(0.5, 30, picks=eeg_picks)\n",
    "    \n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell opens the ICA file for Participant PNUM\n",
    "\n",
    "def get_ica_data_from_file(filtered_data, PNUM):\n",
    "    ica = mne.preprocessing.read_ica('ica_data/P' + PNUM + '-ica.fif')\n",
    "\n",
    "    # apply the transformation\n",
    "    postica_data = ica.apply(filtered_data, exclude=ica.exclude)\n",
    "    return postica_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Original code from https://github.com/sstober/openmiir-rl-2016/blob/master/openmiir/events.py#L21 and adapted \n",
    "KEYSTROKE_BASE_ID = 2000\n",
    "TIME_INDEX = 0\n",
    "ID_INDEX = 1\n",
    "\n",
    "# returns two things, a True if Not Noise boolean and a tuple with three elements:\n",
    "# 0- this is lyrical (0-2) <- YLABEL\n",
    "# 1- start time (onsettime + cue duration if condition 1/2, else just onsettime)\n",
    "# 2- end time (starttime + duration of song without cue)\n",
    "def get_event_data(event_times_ids, events_index, music_version):\n",
    "    event_id = event_times_ids[events_index[0]][ID_INDEX]\n",
    "\n",
    "    if event_id < 1000:\n",
    "        \"\"\"\n",
    "        Event Ids < 1000 are trial labels\n",
    "        with the last digit indicating the condition\n",
    "                1 : 'perception',\n",
    "                2 : 'cued imag',\n",
    "                3 : 'imag fix cross',\n",
    "                4 : 'imagination',\n",
    "        and the remaining digits referring to the stimulus id.\n",
    "        \"\"\"\n",
    "        stimulus_id, condition = decode_event_id(event_id)\n",
    "        \n",
    "        stimulus_info = get_vers_stim_dict(music_version)[stimulus_id]\n",
    "        cue_length = stimulus_info['cue_length']\n",
    "        song_length = stimulus_info['song_length']\n",
    "        \n",
    "        events_index[0] += 1\n",
    "        \n",
    "        #print(get_id_to_song_name(stimulus_id))\n",
    "        \n",
    "        # get time of audio onset for this stimulus\n",
    "        while event_times_ids[events_index[0]][ID_INDEX] != 1000:\n",
    "            #print(\"Expected an audio onset event but got {}\".format(event_times_ids[events_index[0]]))\n",
    "            events_index[0] += 1\n",
    "            \n",
    "        audio_onset_time = event_times_ids[events_index[0]][TIME_INDEX]\n",
    "        start_time = (audio_onset_time + cue_length) if condition in [1,2] else audio_onset_time\n",
    "        end_time = start_time + song_length\n",
    "        \n",
    "        # move the pointer by 1 to prep next call to get_event_data\n",
    "        events_index[0] += 1\n",
    "        \n",
    "        return True, (stimulus_info[\"audio_type\"], start_time, end_time)\n",
    "    else:\n",
    "        # move the pointer by 1 to prep next call to get_event_data\n",
    "        events_index[0] += 1\n",
    "        \n",
    "        return {\n",
    "            1111: (False, (\"noise\")),\n",
    "            KEYSTROKE_BASE_ID: (False, 'imagination failed'),\n",
    "            KEYSTROKE_BASE_ID+1: (False, 'imagination okay')\n",
    "        }[event_id]\n",
    "    \n",
    "    \n",
    "# convert event id to stimulus (song num) and condition (1-4)\n",
    "def decode_event_id(event_id):\n",
    "    if event_id < 1000:\n",
    "        stimulus_id = event_id // 10\n",
    "        condition = event_id % 10\n",
    "        return stimulus_id, condition\n",
    "    else:\n",
    "        return event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_data_list(event_times_ids, p):\n",
    "    events_data_list = []\n",
    "    events_index = [0]\n",
    "    music_version = get_participant_vers(p)\n",
    "\n",
    "    while len(events_data_list) < 50:\n",
    "        is_audio, event_data = get_event_data(event_times_ids, events_index, music_version)\n",
    "        if is_audio:\n",
    "            # ignore AudioType.NONLYRICAL_LYRICAL (songs that have lyrics but played w/o lyrics)\n",
    "            if event_data[0] == AudioType.LYRICAL or event_data[0] == AudioType.NON_LYRICAL:\n",
    "                events_data_list.append(event_data)\n",
    "    \n",
    "    return events_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channels_eeg_data(event_matrix, start_time, end_time, ch_names, postica_data):\n",
    "    # for each channel\n",
    "    # extract this individual event's eeg data btwn start and endtime\n",
    "    for i in range(len(ch_names)):\n",
    "        channel_index = 0\n",
    "        sampling_freq = postica_data.info['sfreq']\n",
    "        start_stop_seconds = np.array([start_time, end_time])\n",
    "        start_sample, stop_sample = (start_stop_seconds * sampling_freq).astype(int)\n",
    "        \n",
    "        # returns a tuple, see https://mne.tools/dev/auto_tutorials/raw/10_raw_overview.html\n",
    "        ch_selection = postica_data[channel_index, start_sample:stop_sample]\n",
    "        # append eeg data list to eventMatrix\n",
    "        event_matrix.append(ch_selection) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file raw_data\\P01-raw.fif...\n",
      "Isotrak not found\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64)  idle\n",
      "    Range : 0 ... 2478165 =      0.000 ...  4840.166 secs\n",
      "Ready.\n",
      "Removing projector <Projection | Average EEG reference, active : False, n_channels : 64>\n",
      "dropped: P8\n",
      "dropped: P10\n",
      "dropped: T8\n",
      "Reading 0 ... 2478165  =      0.000 ...  4840.166 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 3381 samples (6.604 sec)\n",
      "\n",
      "Reading ica_data/P01-ica.fif ...\n",
      "Isotrak not found\n",
      "Now restoring ICA solution ...\n",
      "Ready.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (61 components)\n",
      "    Zeroing out 6 ICA components\n",
      "    Projecting back using 61 PCA components\n",
      "540 events found\n",
      "Event IDs: [  11   12   13   14   21   22   23   24   31   32   33   34   41   42\n",
      "   43   44  111  112  113  114  121  122  123  124  131  132  133  134\n",
      "  141  142  143  144  211  212  213  214  221  222  223  224  231  232\n",
      "  233  234  241  242  243  244 1000 1111 2001]\n",
      "Opening raw data file raw_data\\P04-raw.fif...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "fname does not exist: C:\\Users\\t\\Documents\\GitHub\\COGS189-openmiir-Glissando-Goblins\\raw_data\\P04-raw.fif",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-758ae4edc136>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mget_participant_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# load ica data for participant\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mfiltered_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_participant_filtered_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mpostica_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_ica_data_from_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-7bbd990424b6>\u001b[0m in \u001b[0;36mget_participant_filtered_data\u001b[1;34m(PNUM)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_participant_filtered_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPNUM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdata_raw_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'raw_data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'P'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mPNUM\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'-raw.fif'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mraw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_raw_fif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_raw_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# remove mastoid channels if present\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mne\\io\\fiff\\raw.py\u001b[0m in \u001b[0;36mread_raw_fif\u001b[1;34m(fname, allow_maxshield, preload, on_split_missing, verbose)\u001b[0m\n\u001b[0;32m    471\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mversionadded\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m     \"\"\"\n\u001b[1;32m--> 473\u001b[1;33m     return Raw(fname=fname, allow_maxshield=allow_maxshield,\n\u001b[0m\u001b[0;32m    474\u001b[0m                \u001b[0mpreload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreload\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m                on_split_missing=on_split_missing)\n",
      "\u001b[1;32m<decorator-gen-229>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fname, allow_maxshield, preload, on_split_missing, verbose)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mne\\io\\fiff\\raw.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fname, allow_maxshield, preload, on_split_missing, verbose)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mnext_fname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_fname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer_size_sec\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m                 self._read_raw_file(next_fname, allow_maxshield,\n\u001b[0m\u001b[0;32m     82\u001b[0m                                     preload, do_check_ext)\n\u001b[0;32m     83\u001b[0m             \u001b[0mdo_check_ext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-230>\u001b[0m in \u001b[0;36m_read_raw_file\u001b[1;34m(self, fname, allow_maxshield, preload, do_check_ext, verbose)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mne\\io\\fiff\\raw.py\u001b[0m in \u001b[0;36m_read_raw_file\u001b[1;34m(self, fname, allow_maxshield, preload, do_check_ext, verbose)\u001b[0m\n\u001b[0;32m    144\u001b[0m                 \u001b[0mcheck_fname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'raw'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m             \u001b[1;31m# filename\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m             \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_fname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'read'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fname'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m             \u001b[0mext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m             \u001b[0mwhole_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreload\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m'.gz'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mext\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mne\\utils\\check.py\u001b[0m in \u001b[0;36m_check_fname\u001b[1;34m(fname, overwrite, must_exist, name, need_dir)\u001b[0m\n\u001b[0;32m    184\u001b[0m                     f'{name} does not have read permissions: {fname}')\n\u001b[0;32m    185\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmust_exist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{name} does not exist: {fname}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: fname does not exist: C:\\Users\\t\\Documents\\GitHub\\COGS189-openmiir-Glissando-Goblins\\raw_data\\P04-raw.fif"
     ]
    }
   ],
   "source": [
    "## This cell prepares X_list and Y_list (data and labels)\n",
    "\n",
    "X_list = []\n",
    "Y_list = []\n",
    "monster_matrix = [] # list of matrices\n",
    "\n",
    "for part in get_participant_list():\n",
    "    # load ica data for participant\n",
    "    filtered_data = get_participant_filtered_data(part)\n",
    "    postica_data = get_ica_data_from_file(filtered_data, part)\n",
    "    \n",
    "    # from ica data, get stimuli events\n",
    "    events = mne.find_events(postica_data)\n",
    "\n",
    "    # creates tuples of (event_time, event_id)\n",
    "    event_times_ids = [(events[:][i][0], events[:][i][2]) for i in range(len(events))]\n",
    "    \n",
    "    # get a list of event datas (enum, starttime, endtime)\n",
    "    events_list = get_event_data_list(event_times_ids, part)\n",
    "    \n",
    "    # for each event in event datas\n",
    "    for audio_type,start_time,end_time in events_list:\n",
    "        event_matrix = [] # list of lists\n",
    "\n",
    "        # get eeg data for all 62 channels, put into event_matrix\n",
    "        eeg_ch_names = postica_data.ch_names[:62]\n",
    "        get_channels_eeg_data(event_matrix, start_time, end_time, eeg_ch_names, postica_data)\n",
    "\n",
    "        # call normalize on event_matrix\n",
    "      \n",
    "        # append event_matrix to monster_matrix\n",
    "        monster_matrix.append(event_matrix)\n",
    "\n",
    "#         Y_list.append(audio_type)=\n",
    "        \n",
    "        # 0 for non-lyrical, 1 for lyrical\n",
    "        Y_list.append(1) if audio_type == AudioType.LYRICAL else Y_list.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XList = pca on monstermatrix for feature vector (SOUMYA AND CHRIS)\n",
    "# make final list of feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data using (training vs testing)\n",
    "# test_size: what proportion of original data is used for test set\n",
    "train_data, test_data, train_lbl, test_lbl = train_test_split(X_list, Y_list, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcAccuracy(predictions, y):\n",
    "    # True positives, false positives, etc.\n",
    "    TP_ = np.logicaland(predictions, y)\n",
    "    FP = np.logical_and(predictions, np.logicalnot(y))\n",
    "    TN = np.logical_and(np.logical_not(predictions), np.logicalnot(y))\n",
    "    FN = np.logical_and(np.logicalnot(predictions), y)\n",
    "\n",
    "    TP = sum(TP)\n",
    "    FP = sum(FP)\n",
    "    TN = sum(TN)\n",
    "    FN = sum(FN_)\n",
    "    \n",
    "    accuracy = (TP + TN)/(TP + FP + TN + FN)\n",
    "    print('Accuracy:{}'.format(accuracy))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform classification using SVM\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "clf = svm.LinearSVC()\n",
    "clf.fit(train_data, train_lbl)\n",
    "y_pred = clf.predict(test_data)\n",
    "\n",
    "# compare predictions for accuracy\n",
    "accuracy = calcAccuracy(y_pred, Y_list)\n",
    "\n",
    "# we could compare accuracy linearSVC and just SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
