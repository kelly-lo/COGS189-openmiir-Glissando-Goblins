{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from AudioOnsetUtils import *\n",
    "\n",
    "RAW_EOG_CHANNELS = [u'EXG1', u'EXG2', u'EXG3', u'EXG4']\n",
    "MASTOID_CHANNELS = [u'EXG5', u'EXG6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell gets filtered data so we can open ICA for Participant PNUM\n",
    "\n",
    "def get_participant_filtered_data(PNUM):\n",
    "    data_raw_file = os.path.join('raw_data', 'P' + PNUM + '-raw.fif')\n",
    "    raw = mne.io.read_raw_fif(data_raw_file)\n",
    "\n",
    "    # remove mastoid channels if present \n",
    "    if MASTOID_CHANNELS[0] in raw.ch_names:\n",
    "        mne.io.set_eeg_reference(raw.load_data(), MASTOID_CHANNELS, copy=False) # inplace\n",
    "        raw.drop_channels(MASTOID_CHANNELS)\n",
    "\n",
    "    # Drop bad channels - in place on raw\n",
    "    for bad_channel in raw.info['bads']:\n",
    "        raw.drop_channels(bad_channel)\n",
    "#         print(\"dropped: \" + bad_channel)\n",
    "\n",
    "    eeg_picks = mne.pick_types(raw.info, meg=False, eeg=True, eog=False, stim=False, exclude=[])\n",
    "\n",
    "    # bandpass filter - keeping a frequency range between 0.5 (high pass filter) and 30 Hz (low pass filter)\n",
    "    filtered_data = raw.load_data().filter(0.5, 30, picks=eeg_picks)\n",
    "    \n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell opens the ICA file for Participant PNUM\n",
    "\n",
    "def get_ica_data_from_file(filtered_data, PNUM):\n",
    "    ica = mne.preprocessing.read_ica('ica_data/P' + PNUM + '-ica.fif')\n",
    "\n",
    "    # apply the transformation\n",
    "    postica_data = ica.apply(filtered_data, exclude=ica.exclude)\n",
    "    return postica_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Original code from https://github.com/sstober/openmiir-rl-2016/blob/master/openmiir/events.py#L21 and adapted \n",
    "KEYSTROKE_BASE_ID = 2000\n",
    "TIME_INDEX = 0\n",
    "ID_INDEX = 1\n",
    "\n",
    "# returns two things, a True if Not Noise boolean and a tuple with three elements:\n",
    "# 0- this is lyrical (0-2) <- YLABEL\n",
    "# 1- start time (onsettime + cue duration if condition 1/2, else just onsettime)\n",
    "# 2- end time (starttime + duration of song without cue)\n",
    "def get_event_data(event_times_ids, events_index, music_version):\n",
    "    event_id = event_times_ids[events_index[0]][ID_INDEX]\n",
    "\n",
    "    if event_id < 1000:\n",
    "        \"\"\"\n",
    "        Event Ids < 1000 are trial labels\n",
    "        with the last digit indicating the condition\n",
    "                1 : 'perception',\n",
    "                2 : 'cued imag',\n",
    "                3 : 'imag fix cross',\n",
    "                4 : 'imagination',\n",
    "        and the remaining digits referring to the stimulus id.\n",
    "        \"\"\"\n",
    "        stimulus_id, condition = decode_event_id(event_id)\n",
    "        \n",
    "        stimulus_info = get_vers_stim_dict(music_version)[stimulus_id]\n",
    "        cue_length = stimulus_info['cue_length']\n",
    "        song_length = stimulus_info['song_length']\n",
    "        \n",
    "        events_index[0] += 1\n",
    "        \n",
    "        #print(get_id_to_song_name(stimulus_id))\n",
    "        \n",
    "        # get time of audio onset for this stimulus\n",
    "        while event_times_ids[events_index[0]][ID_INDEX] != 1000:\n",
    "            #print(\"Expected an audio onset event but got {}\".format(event_times_ids[events_index[0]]))\n",
    "            events_index[0] += 1\n",
    "            \n",
    "        audio_onset_time = event_times_ids[events_index[0]][TIME_INDEX]\n",
    "        start_time = (audio_onset_time + cue_length) if condition in [1,2] else audio_onset_time\n",
    "        end_time = start_time + song_length\n",
    "        \n",
    "        # move the pointer by 1 to prep next call to get_event_data\n",
    "        events_index[0] += 1\n",
    "        \n",
    "        return True, (stimulus_info[\"audio_type\"], start_time, end_time)\n",
    "    else:\n",
    "        # move the pointer by 1 to prep next call to get_event_data\n",
    "        events_index[0] += 1\n",
    "        \n",
    "        return {\n",
    "            1111: (False, (\"noise\")),\n",
    "            KEYSTROKE_BASE_ID: (False, 'imagination failed'),\n",
    "            KEYSTROKE_BASE_ID+1: (False, 'imagination okay')\n",
    "        }[event_id]\n",
    "    \n",
    "    \n",
    "# convert event id to stimulus (song num) and condition (1-4)\n",
    "def decode_event_id(event_id):\n",
    "    if event_id < 1000:\n",
    "        stimulus_id = event_id // 10\n",
    "        condition = event_id % 10\n",
    "        return stimulus_id, condition\n",
    "    else:\n",
    "        return event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_data_list(event_times_ids, p):\n",
    "    events_data_list = []\n",
    "    events_index = [0]\n",
    "    music_version = get_participant_vers(p)\n",
    "\n",
    "    while len(events_data_list) < 50:\n",
    "        is_audio, event_data = get_event_data(event_times_ids, events_index, music_version)\n",
    "        if is_audio:\n",
    "            # ignore AudioType.NONLYRICAL_LYRICAL (songs that have lyrics but played w/o lyrics)\n",
    "            if event_data[0] == AudioType.LYRICAL or event_data[0] == AudioType.NON_LYRICAL:\n",
    "                events_data_list.append(event_data)\n",
    "    \n",
    "    return events_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channels_eeg_data(event_matrix, start_time, end_time, ch_names, postica_data):\n",
    "    # for each channel\n",
    "    # extract this individual event's eeg data btwn start and endtime\n",
    "    sampling_freq = postica_data.info['sfreq']\n",
    "\n",
    "    for i in range(len(ch_names)):\n",
    "        start_stop_seconds = np.array([11, 13])\n",
    "        start_sample, stop_sample = (start_stop_seconds * sampling_freq).astype(int)\n",
    "        \n",
    "        # returns a tuple, see https://mne.tools/dev/auto_tutorials/raw/10_raw_overview.html\n",
    "        #print(postica_data[i, start_sample:stop_sample])\n",
    "        ch_selection = postica_data[i, start_sample:stop_sample]\n",
    "        \n",
    "#         print(\"==================\")\n",
    "#         print(ch_selection)\n",
    "        \n",
    "        # append eeg data list to eventMatrix\n",
    "        event_matrix.append(ch_selection) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file raw_data\\P01-raw.fif...\n",
      "Isotrak not found\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64)  idle\n",
      "    Range : 0 ... 2478165 =      0.000 ...  4840.166 secs\n",
      "Ready.\n",
      "Removing projector <Projection | Average EEG reference, active : False, n_channels : 64>\n",
      "Reading 0 ... 2478165  =      0.000 ...  4840.166 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 3381 samples (6.604 sec)\n",
      "\n",
      "Reading ica_data/P01-ica.fif ...\n",
      "Isotrak not found\n",
      "Now restoring ICA solution ...\n",
      "Ready.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (61 components)\n",
      "    Zeroing out 6 ICA components\n",
      "    Projecting back using 61 PCA components\n",
      "540 events found\n",
      "Event IDs: [  11   12   13   14   21   22   23   24   31   32   33   34   41   42\n",
      "   43   44  111  112  113  114  121  122  123  124  131  132  133  134\n",
      "  141  142  143  144  211  212  213  214  221  222  223  224  231  232\n",
      "  233  234  241  242  243  244 1000 1111 2001]\n"
     ]
    }
   ],
   "source": [
    "## This cell prepares X_list and Y_list (data and labels)\n",
    "\n",
    "X_list = []\n",
    "Y_list = []\n",
    "monster_matrix = [] # list of matrices\n",
    "\n",
    "#for part in get_participant_list():\n",
    "for part in [\"01\"]:\n",
    "    # load ica data for participant\n",
    "    filtered_data = get_participant_filtered_data(part)\n",
    "    postica_data = get_ica_data_from_file(filtered_data, part)\n",
    "    \n",
    "    # from ica data, get stimuli events\n",
    "    events = mne.find_events(postica_data)\n",
    "\n",
    "    # creates tuples of (event_time, event_id)\n",
    "    event_times_ids = [(events[:][i][0], events[:][i][2]) for i in range(len(events))]\n",
    "    \n",
    "    # get a list of event datas (enum, starttime, endtime)\n",
    "    events_list = get_event_data_list(event_times_ids, part)\n",
    "    \n",
    "    # for each event in event datas\n",
    "    for audio_type,start_time,end_time in events_list:\n",
    "        event_matrix = [] # list of lists\n",
    "\n",
    "        # get eeg data for all 62 channels, put into event_matrix\n",
    "        eeg_ch_names = postica_data.ch_names[:62]\n",
    "        get_channels_eeg_data(event_matrix, start_time, end_time, eeg_ch_names, postica_data)\n",
    "\n",
    "        # call normalize on event_matrix\n",
    "      \n",
    "        # append event_matrix to monster_matrix\n",
    "        monster_matrix.append(event_matrix)\n",
    "        \n",
    "        # 0 for non-lyrical, 1 for lyrical\n",
    "        Y_list.append(1) if audio_type == AudioType.LYRICAL else Y_list.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code adapted from https://ataspinar.com/2018/12/21/a-guide-for-using-the-wavelet-transform-in-machine-learning/\n",
    "\n",
    "def calculate_entropy(list_values):\n",
    "    counter_values = Counter(list_values).most_common()\n",
    "    probabilities = [elem[1]/len(list_values) for elem in counter_values]\n",
    "    entropy=scipy.stats.entropy(probabilities)\n",
    "    return entropy\n",
    " \n",
    "def calculate_statistics(list_values):\n",
    "    n5 = np.nanpercentile(list_values, 5)\n",
    "    n25 = np.nanpercentile(list_values, 25)\n",
    "    n75 = np.nanpercentile(list_values, 75)\n",
    "    n95 = np.nanpercentile(list_values, 95)\n",
    "    median = np.nanpercentile(list_values, 50)\n",
    "    mean = np.nanmean(list_values)\n",
    "    std = np.nanstd(list_values)\n",
    "    var = np.nanvar(list_values)\n",
    "    rms = np.nanmean(np.sqrt(list_values**2))\n",
    "    return [n5, n25, n75, n95, median, mean, std, var, rms]\n",
    " \n",
    "def calculate_crossings(list_values):\n",
    "    val_array = list_values\n",
    "    num_zero_crossings = ((val_array[:-1] * val_array[1:]) < 0).sum()\n",
    "    num_mean_crossings = ((val_array[:-1] * val_array[1:]) < np.nanmean(list_values)).sum()  \n",
    "    return [num_zero_crossings, num_mean_crossings]\n",
    " \n",
    "def get_features(list_values):\n",
    "    entropy = calculate_entropy(list_values)\n",
    "    crossings = calculate_crossings(list_values)\n",
    "    statistics = calculate_statistics(list_values)\n",
    "    return [entropy] + crossings + statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://ataspinar.com/2018/12/21/a-guide-for-using-the-wavelet-transform-in-machine-learning/\n",
    "WAVELET_NAME = 'db2' \n",
    "\n",
    "def get_dataset_features(dataset):\n",
    "    feature_vectors = []\n",
    "    \n",
    "    for event_eeg_index in range(0, len(dataset)):\n",
    "        event_features = []\n",
    "        \n",
    "        for channel_index in range(0, len(dataset[event_eeg_index])):\n",
    "            channel_signal = dataset[event_eeg_index][channel_index]\n",
    "            print(channel_signal)\n",
    "            \n",
    "            coeff_list = pywt.wavedec(channel_signal, WAVELET_NAME)\n",
    "            #print(coeff_list)\n",
    "            for coeff in coeff_list:\n",
    "                #print(coeff)\n",
    "                pass\n",
    "                #event_features += get_features(coeff)\n",
    "                \n",
    "        feature_vectors.append(event_features)\n",
    "        \n",
    "    X = np.array(feature_vectors)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(monster_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_features(monster_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data using (training vs testing)\n",
    "# test_size: what proportion of original data is used for test set\n",
    "train_data, test_data, train_lbl, test_lbl = train_test_split(X_list, Y_list, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM and Check Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcAccuracy(predictions, y):\n",
    "    # True positives, false positives, etc.\n",
    "    TP_ = np.logicaland(predictions, y)\n",
    "    FP = np.logical_and(predictions, np.logicalnot(y))\n",
    "    TN = np.logical_and(np.logical_not(predictions), np.logicalnot(y))\n",
    "    FN = np.logical_and(np.logicalnot(predictions), y)\n",
    "\n",
    "    TP = sum(TP)\n",
    "    FP = sum(FP)\n",
    "    TN = sum(TN)\n",
    "    FN = sum(FN_)\n",
    "    \n",
    "    accuracy = (TP + TN)/(TP + FP + TN + FN)\n",
    "    print('Accuracy:{}'.format(accuracy))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform classification using SVM\n",
    "clf = svm.LinearSVC()\n",
    "clf.fit(train_data, train_lbl)\n",
    "y_pred = clf.predict(test_data)\n",
    "\n",
    "# compare predictions for accuracy\n",
    "accuracy = calcAccuracy(y_pred, Y_list)\n",
    "\n",
    "# future work: we could compare accuracy linearSVC and just SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
