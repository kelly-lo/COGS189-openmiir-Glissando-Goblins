{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from AudioOnsetUtils import *\n",
    "\n",
    "RAW_EOG_CHANNELS = [u'EXG1', u'EXG2', u'EXG3', u'EXG4']\n",
    "MASTOID_CHANNELS = [u'EXG5', u'EXG6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file raw_data\\P14-raw.fif...\n",
      "Isotrak not found\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 66)  idle\n",
      "    Range : 0 ... 2465433 =      0.000 ...  4815.299 secs\n",
      "Ready.\n",
      "Reading 0 ... 2465433  =      0.000 ...  4815.299 secs...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying a custom ('EEG',) reference.\n",
      "Removing existing average EEG reference projection.\n",
      "dropped: T7\n",
      "dropped: F7\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 3381 samples (6.604 sec)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## This cell gets filtered data so we can open ICA for Participant PNUM\n",
    "\n",
    "# set the participant number\n",
    "PNUM = \"14\"\n",
    "\n",
    "data_raw_file = os.path.join('raw_data', 'P' + PNUM + '-raw.fif')\n",
    "raw = mne.io.read_raw_fif(data_raw_file)\n",
    "\n",
    "# remove mastoid channels if present \n",
    "if MASTOID_CHANNELS[0] in raw.ch_names:\n",
    "    mne.io.set_eeg_reference(raw.load_data(), MASTOID_CHANNELS, copy=False) # inplace\n",
    "    raw.drop_channels(MASTOID_CHANNELS)\n",
    "    \n",
    "# Drop bad channels - in place on raw\n",
    "for bad_channel in raw.info['bads']:\n",
    "    raw.drop_channels(bad_channel)\n",
    "    print(\"dropped: \" + bad_channel)\n",
    "    \n",
    "eeg_picks = mne.pick_types(raw.info, meg=False, eeg=True, eog=False, stim=False, exclude=[])\n",
    "\n",
    "# bandpass filter - keeping a frequency range between 0.5 (high pass filter) and 30 Hz (low pass filter)\n",
    "filtered_data = raw.load_data().filter(0.5, 30, picks=eeg_picks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ica_data/P14-ica.fif ...\n",
      "Isotrak not found\n",
      "Now restoring ICA solution ...\n",
      "Ready.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (62 components)\n",
      "    Zeroing out 6 ICA components\n",
      "    Projecting back using 62 PCA components\n"
     ]
    }
   ],
   "source": [
    "## This cell opens the ICA file for Participant NUM\n",
    "\n",
    "ica = mne.preprocessing.read_ica('ica_data/P' + PNUM + '-ica.fif')\n",
    "# apply the transformation\n",
    "postica_data = ica.apply(filtered_data, exclude=ica.exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540 events found\n",
      "Event IDs: [  11   12   13   14   21   22   23   24   31   32   33   34   41   42\n",
      "   43   44  111  112  113  114  121  122  123  124  131  132  133  134\n",
      "  141  142  143  144  211  212  213  214  221  222  223  224  231  232\n",
      "  233  234  241  242  243  244 1000 1111 2000 2001]\n",
      "[(512, 121), (520, 1000)]\n"
     ]
    }
   ],
   "source": [
    "events = mne.find_events(postica_data)\n",
    "NUM_EVENTS = len(events) # num of first events we care about per participant\n",
    "\n",
    "# creates tuples of (event_time, event_id)\n",
    "event_times_ids = [(events[:][i][0], events[:][i][2]) for i in range(NUM_EVENTS)]\n",
    "print(event_times_ids[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Original code from https://github.com/sstober/openmiir-rl-2016/blob/master/openmiir/events.py#L21 and adapted \n",
    "KEYSTROKE_BASE_ID = 2000\n",
    "TIME_INDEX = 0\n",
    "ID_INDEX = 1\n",
    "\n",
    "# returns two things, a True if Not Noise boolean and a tuple with three elements:\n",
    "# 0- this is lyrical (0-2) <- YLABEL\n",
    "# 1- start time (onsettime + cue duration if condition 1/2, else just onsettime)\n",
    "# 2- end time (starttime + duration of song without cue)\n",
    "def get_event_data(event_times_ids, events_index, music_version):\n",
    "    event_id = event_times_ids[events_index[0]][ID_INDEX]\n",
    "\n",
    "    if event_id < 1000:\n",
    "        \"\"\"\n",
    "        Event Ids < 1000 are trial labels\n",
    "        with the last digit indicating the condition\n",
    "                1 : 'perception',\n",
    "                2 : 'cued imag',\n",
    "                3 : 'imag fix cross',\n",
    "                4 : 'imagination',\n",
    "        and the remaining digits referring to the stimulus id.\n",
    "        \"\"\"\n",
    "        stimulus_id, condition = decode_event_id(event_id)\n",
    "        \n",
    "        stimulus_info = get_vers_stim_dict(music_version)[stimulus_id]\n",
    "        cue_length = stimulus_info['cue_length']\n",
    "        song_length = stimulus_info['song_length']\n",
    "        \n",
    "        events_index[0] += 1\n",
    "        \n",
    "        #print(get_id_to_song_name(stimulus_id))\n",
    "        \n",
    "        # get time of audio onset for this stimulus\n",
    "        while event_times_ids[events_index[0]][ID_INDEX] != 1000:\n",
    "            print(\"Expected an audio onset event but got {}\".format(event_times_ids[events_index[0]]))\n",
    "            events_index[0] += 1\n",
    "            \n",
    "        audio_onset_time = event_times_ids[events_index[0]][TIME_INDEX]\n",
    "        start_time = (audio_onset_time + cue_length) if condition in [1,2] else audio_onset_time\n",
    "        end_time = start_time + song_length\n",
    "        \n",
    "        # move the pointer by 1 to prep next call to get_event_data\n",
    "        events_index[0] += 1\n",
    "        \n",
    "        return True, (stimulus_info[\"audio_type\"], start_time, end_time)\n",
    "    else:\n",
    "        # move the pointer by 1 to prep next call to get_event_data\n",
    "        events_index[0] += 1\n",
    "        \n",
    "        return {\n",
    "            1111: (False, (\"noise\")),\n",
    "            KEYSTROKE_BASE_ID: (False, 'imagination failed'),\n",
    "            KEYSTROKE_BASE_ID+1: (False, 'imagination okay')\n",
    "        }[event_id]\n",
    "    \n",
    "    \n",
    "# convert event id to stimulus (song num) and condition (1-4)\n",
    "def decode_event_id(event_id):\n",
    "    if event_id < 1000:\n",
    "        stimulus_id = event_id // 10\n",
    "        condition = event_id % 10\n",
    "        return stimulus_id, condition\n",
    "    else:\n",
    "        return event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_index = [0]\n",
    "music_version = get_participant_vers(\"01\")\n",
    "is_stim_event, event_data = get_event_data(event_times_ids, events_index, music_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<AudioType.NONLYRICAL_LYRICAL: 1>, 521.869, 529.6427)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_names = postica_data.ch_names[:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ch_names)):\n",
    "    channel_index = 0\n",
    "    sampling_freq = raw.info['sfreq']\n",
    "    start_stop_seconds = np.array([event_data[-2], event_data[-1]])\n",
    "    start_sample, stop_sample = (start_stop_seconds * sampling_freq).astype(int)\n",
    "    raw_selection = postica_data[channel_index, start_sample:(stop_sample+9)]\n",
    "    #print(raw_selection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
