{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RAW_EOG_CHANNELS = [u'EXG1', u'EXG2', u'EXG3', u'EXG4']\n",
    "MASTOID_CHANNELS = [u'EXG5', u'EXG6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file raw_data\\P14-raw.fif...\n",
      "Isotrak not found\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 66)  idle\n",
      "    Range : 0 ... 2465433 =      0.000 ...  4815.299 secs\n",
      "Ready.\n",
      "Reading 0 ... 2465433  =      0.000 ...  4815.299 secs...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying a custom ('EEG',) reference.\n",
      "Removing existing average EEG reference projection.\n",
      "dropped: T7\n",
      "dropped: F7\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 3381 samples (6.604 sec)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## This cell gets filtered data so we can open ICA for Participant PNUM\n",
    "\n",
    "# set the participant number\n",
    "PNUM = \"14\"\n",
    "\n",
    "data_raw_file = os.path.join('raw_data', 'P' + PNUM + '-raw.fif')\n",
    "raw = mne.io.read_raw_fif(data_raw_file)\n",
    "\n",
    "# remove mastoid channels if present \n",
    "if MASTOID_CHANNELS[0] in raw.ch_names:\n",
    "    mne.io.set_eeg_reference(raw.load_data(), MASTOID_CHANNELS, copy=False) # inplace\n",
    "    raw.drop_channels(MASTOID_CHANNELS)\n",
    "    \n",
    "# Drop bad channels - in place on raw\n",
    "for bad_channel in raw.info['bads']:\n",
    "    raw.drop_channels(bad_channel)\n",
    "    print(\"dropped: \" + bad_channel)\n",
    "    \n",
    "eeg_picks = mne.pick_types(raw.info, meg=False, eeg=True, eog=False, stim=False, exclude=[])\n",
    "\n",
    "# bandpass filter - keeping a frequency range between 0.5 (high pass filter) and 30 Hz (low pass filter)\n",
    "filtered_data = raw.load_data().filter(0.5, 30, picks=eeg_picks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ica_data/P14-ica.fif ...\n",
      "Isotrak not found\n",
      "Now restoring ICA solution ...\n",
      "Ready.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (62 components)\n",
      "    Zeroing out 6 ICA components\n",
      "    Projecting back using 62 PCA components\n"
     ]
    }
   ],
   "source": [
    "## This cell opens the ICA file for Participant NUM\n",
    "\n",
    "ica = mne.preprocessing.read_ica('ica_data/P' + PNUM + '-ica.fif')\n",
    "# apply the transformation\n",
    "postica_data = ica.apply(filtered_data, exclude=ica.exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540 events found\n",
      "Event IDs: [  11   12   13   14   21   22   23   24   31   32   33   34   41   42\n",
      "   43   44  111  112  113  114  121  122  123  124  131  132  133  134\n",
      "  141  142  143  144  211  212  213  214  221  222  223  224  231  232\n",
      "  233  234  241  242  243  244 1000 1111 2000 2001]\n",
      "[(512, 121), (520, 1000)]\n"
     ]
    }
   ],
   "source": [
    "events = mne.find_events(postica_data)\n",
    "NUM_EVENTS = len(events) # num of first events we care about per participant\n",
    "\n",
    "# creates tuples of (event_time, event_id)\n",
    "event_times_ids = [(events[:][i][0], events[:][i][2]) for i in range(NUM_EVENTS)]\n",
    "print(event_times_ids[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Original code from https://github.com/sstober/openmiir-rl-2016/blob/master/openmiir/events.py#L21 and adapted \n",
    "KEYSTROKE_BASE_ID = 2000\n",
    "TIME_INDEX = 0\n",
    "ID_INDEX = 1\n",
    "\n",
    "# returns two things, a True if Not Noise boolean and a tuple with three elements:\n",
    "# 0- this is lyrical (0-2) <- YLABEL\n",
    "# 1- start time (onsettime + cue duration if condition 1/2, else just onsettime)\n",
    "# 2- end time (starttime + duration of song without cue)\n",
    "def get_event_data(event_times_ids, events_index, music_version):\n",
    "    event_id = event_times_ids[events_index[0]][TIME_INDEX]\n",
    "\n",
    "    if event_id < 1000:\n",
    "        \"\"\"\n",
    "        Event Ids < 1000 are trial labels\n",
    "        with the last digit indicating the condition\n",
    "                1 : 'perception',\n",
    "                2 : 'cued imag',\n",
    "                3 : 'imag fix cross',\n",
    "                4 : 'imagination',\n",
    "        and the remaining digits referring to the stimulus id.\n",
    "        \"\"\"\n",
    "        stimulus_id, condition = decode_event_id(event_id)\n",
    "        \n",
    "        stimulus_info = stimuli_meta[music_version][stimulus_id]\n",
    "        cue_length = stimulus_info['cue_length']\n",
    "        song_length = stimulus_info['song_length']\n",
    "        \n",
    "        events_index[0] += 1\n",
    "        \n",
    "        # get time of audio onset for this stimulus\n",
    "        if event_times_ids[events_index[0]][ID_INDEX] != 1000:\n",
    "            print(\"Expected an audio onset event but got {}\".format(event_times_ids[events_index[0]]))\n",
    "            raise ValueError\n",
    "            return False, \"expected audio onset error\"\n",
    "            \n",
    "        audio_onset_time = event_times_ids[events_index[0]][TIME_INDEX]\n",
    "        start_time = (audio_onset_time + cue_length) if condition in [1,2] else audio_onset_time\n",
    "        end_time = start_time + song_length\n",
    "        \n",
    "        # move the pointer by 1 to prep next call to get_event_data\n",
    "        event_id_index[0] += 1\n",
    "        \n",
    "        return True, (stimulus_info[\"audio_type\"], start_time, end_time)\n",
    "    else:\n",
    "        # move the pointer by 1 to prep next call to get_event_data\n",
    "        event_id_index[0] += 1\n",
    "        \n",
    "        return {\n",
    "            #1000: (False, 'audio onset'),\n",
    "            1111: (False, (\"noise\")),\n",
    "            KEYSTROKE_BASE_ID: (False, 'imagination failed'),\n",
    "            KEYSTROKE_BASE_ID+1: (False, 'imagination okay')\n",
    "        }[event_id]\n",
    "    \n",
    "    \n",
    "# convert event id to stimulus (song num) and condition (1-4)\n",
    "def decode_event_id(event_id):\n",
    "    if event_id < 1000:\n",
    "        stimulus_id = event_id // 10\n",
    "        condition = event_id % 10\n",
    "        return stimulus_id, condition\n",
    "    else:\n",
    "        return event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stimuli_meta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-5facb82b332c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mevents_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmusic_version\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mget_event_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent_times_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevents_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmusic_version\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-83-5f12c2cff3b9>\u001b[0m in \u001b[0;36mget_event_data\u001b[1;34m(event_times_ids, events_index, music_version)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mstimulus_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcondition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecode_event_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mstimulus_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstimuli_meta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmusic_version\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstimulus_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mcue_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstimulus_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cue_length'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0msong_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstimulus_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'song_length'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stimuli_meta' is not defined"
     ]
    }
   ],
   "source": [
    "events_index = [0]\n",
    "music_version = 1\n",
    "get_event_data(event_times_ids, events_index, music_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
