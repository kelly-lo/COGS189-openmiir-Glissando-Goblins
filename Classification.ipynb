{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from AudioOnsetUtils import *\n",
    "\n",
    "RAW_EOG_CHANNELS = [u'EXG1', u'EXG2', u'EXG3', u'EXG4']\n",
    "MASTOID_CHANNELS = [u'EXG5', u'EXG6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file raw_data/P14-raw.fif...\n",
      "Isotrak not found\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 66)  idle\n",
      "    Range : 0 ... 2465433 =      0.000 ...  4815.299 secs\n",
      "Ready.\n",
      "Reading 0 ... 2465433  =      0.000 ...  4815.299 secs...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying a custom ('EEG',) reference.\n",
      "Removing existing average EEG reference projection.\n",
      "dropped: T7\n",
      "dropped: F7\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 3381 samples (6.604 sec)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## This cell gets filtered data so we can open ICA for Participant PNUM\n",
    "\n",
    "# set the participant number\n",
    "PNUM = \"14\"\n",
    "\n",
    "data_raw_file = os.path.join('raw_data', 'P' + PNUM + '-raw.fif')\n",
    "raw = mne.io.read_raw_fif(data_raw_file)\n",
    "\n",
    "# remove mastoid channels if present \n",
    "if MASTOID_CHANNELS[0] in raw.ch_names:\n",
    "    mne.io.set_eeg_reference(raw.load_data(), MASTOID_CHANNELS, copy=False) # inplace\n",
    "    raw.drop_channels(MASTOID_CHANNELS)\n",
    "    \n",
    "# Drop bad channels - in place on raw\n",
    "for bad_channel in raw.info['bads']:\n",
    "    raw.drop_channels(bad_channel)\n",
    "    print(\"dropped: \" + bad_channel)\n",
    "    \n",
    "eeg_picks = mne.pick_types(raw.info, meg=False, eeg=True, eog=False, stim=False, exclude=[])\n",
    "\n",
    "# bandpass filter - keeping a frequency range between 0.5 (high pass filter) and 30 Hz (low pass filter)\n",
    "filtered_data = raw.load_data().filter(0.5, 30, picks=eeg_picks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ica_data/P14-ica.fif ...\n",
      "Isotrak not found\n",
      "Now restoring ICA solution ...\n",
      "Ready.\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (62 components)\n",
      "    Zeroing out 6 ICA components\n",
      "    Projecting back using 62 PCA components\n"
     ]
    }
   ],
   "source": [
    "## This cell opens the ICA file for Participant NUM\n",
    "\n",
    "ica = mne.preprocessing.read_ica('ica_data/P' + PNUM + '-ica.fif')\n",
    "# apply the transformation\n",
    "postica_data = ica.apply(filtered_data, exclude=ica.exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540 events found\n",
      "Event IDs: [  11   12   13   14   21   22   23   24   31   32   33   34   41   42\n",
      "   43   44  111  112  113  114  121  122  123  124  131  132  133  134\n",
      "  141  142  143  144  211  212  213  214  221  222  223  224  231  232\n",
      "  233  234  241  242  243  244 1000 1111 2000 2001]\n",
      "[(512, 121), (520, 1000)]\n"
     ]
    }
   ],
   "source": [
    "events = mne.find_events(postica_data)\n",
    "NUM_EVENTS = len(events) # num of first events we care about per participant\n",
    "\n",
    "# creates tuples of (event_time, event_id)\n",
    "event_times_ids = [(events[:][i][0], events[:][i][2]) for i in range(NUM_EVENTS)]\n",
    "print(event_times_ids[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Original code from https://github.com/sstober/openmiir-rl-2016/blob/master/openmiir/events.py#L21 and adapted \n",
    "KEYSTROKE_BASE_ID = 2000\n",
    "TIME_INDEX = 0\n",
    "ID_INDEX = 1\n",
    "\n",
    "# returns two things, a True if Not Noise boolean and a tuple with three elements:\n",
    "# 0- this is lyrical (0-2) <- YLABEL\n",
    "# 1- start time (onsettime + cue duration if condition 1/2, else just onsettime)\n",
    "# 2- end time (starttime + duration of song without cue)\n",
    "def get_event_data(event_times_ids, events_index, music_version):\n",
    "    event_id = event_times_ids[events_index[0]][ID_INDEX]\n",
    "\n",
    "    if event_id < 1000:\n",
    "        \"\"\"\n",
    "        Event Ids < 1000 are trial labels\n",
    "        with the last digit indicating the condition\n",
    "                1 : 'perception',\n",
    "                2 : 'cued imag',\n",
    "                3 : 'imag fix cross',\n",
    "                4 : 'imagination',\n",
    "        and the remaining digits referring to the stimulus id.\n",
    "        \"\"\"\n",
    "        stimulus_id, condition = decode_event_id(event_id)\n",
    "        \n",
    "        stimulus_info = get_vers_stim_dict(music_version)[stimulus_id]\n",
    "        cue_length = stimulus_info['cue_length']\n",
    "        song_length = stimulus_info['song_length']\n",
    "        \n",
    "        events_index[0] += 1\n",
    "        \n",
    "        #print(get_id_to_song_name(stimulus_id))\n",
    "        \n",
    "        # get time of audio onset for this stimulus\n",
    "        while event_times_ids[events_index[0]][ID_INDEX] != 1000:\n",
    "            print(\"Expected an audio onset event but got {}\".format(event_times_ids[events_index[0]]))\n",
    "            events_index[0] += 1\n",
    "            \n",
    "        audio_onset_time = event_times_ids[events_index[0]][TIME_INDEX]\n",
    "        start_time = (audio_onset_time + cue_length) if condition in [1,2] else audio_onset_time\n",
    "        end_time = start_time + song_length\n",
    "        \n",
    "        # move the pointer by 1 to prep next call to get_event_data\n",
    "        events_index[0] += 1\n",
    "        \n",
    "        return True, (stimulus_info[\"audio_type\"], start_time, end_time)\n",
    "    else:\n",
    "        # move the pointer by 1 to prep next call to get_event_data\n",
    "        events_index[0] += 1\n",
    "        \n",
    "        return {\n",
    "            1111: (False, (\"noise\")),\n",
    "            KEYSTROKE_BASE_ID: (False, 'imagination failed'),\n",
    "            KEYSTROKE_BASE_ID+1: (False, 'imagination okay')\n",
    "        }[event_id]\n",
    "    \n",
    "    \n",
    "# convert event id to stimulus (song num) and condition (1-4)\n",
    "def decode_event_id(event_id):\n",
    "    if event_id < 1000:\n",
    "        stimulus_id = event_id // 10\n",
    "        condition = event_id % 10\n",
    "        return stimulus_id, condition\n",
    "    else:\n",
    "        return event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_index = [0]\n",
    "music_version = get_participant_vers(\"01\")\n",
    "is_stim_event, event_data = get_event_data(event_times_ids, events_index, music_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<AudioType.NONLYRICAL_LYRICAL: 1>, 521.869, 529.6427)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_names = postica_data.ch_names[:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ch_names)):\n",
    "    channel_index = 0\n",
    "    sampling_freq = raw.info['sfreq']\n",
    "    start_stop_seconds = np.array([event_data[-2], event_data[-1]])\n",
    "    start_sample, stop_sample = (start_stop_seconds * sampling_freq).astype(int)\n",
    "    raw_selection = postica_data[channel_index, start_sample:(stop_sample+9)]\n",
    "    #print(raw_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_data_list(p_vers):\n",
    "    events_data_list = []\n",
    "    events_index = [0]\n",
    "    music_version = get_participant_vers(p_vers)\n",
    "\n",
    "    while len(events_data_list) < 50:\n",
    "        is_audio, event_data = get_event_data(event_times_ids, events_index, music_version)\n",
    "        if is_audio:\n",
    "            # ignore AudioType.NONLYRICAL_LYRICAL (songs that have lyrics but played w/o lyrics)\n",
    "            if event_data[0] == AudioType.LYRICAL or event_data[0] == AudioType.NON_LYRICAL:\n",
    "                events_data_list.append(event_data)\n",
    "    \n",
    "    return events_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected an audio onset event but got (21617, 1111)\n",
      "Expected an audio onset event but got (50133, 1111)\n",
      "Expected an audio onset event but got (77942, 1111)\n",
      "Expected an audio onset event but got (105307, 1111)\n",
      "Expected an audio onset event but got (138780, 1111)\n",
      "Expected an audio onset event but got (172603, 1111)\n",
      "Expected an audio onset event but got (205513, 1111)\n",
      "Expected an audio onset event but got (230208, 1111)\n",
      "Expected an audio onset event but got (262803, 1111)\n",
      "Expected an audio onset event but got (288607, 1111)\n",
      "Expected an audio onset event but got (326592, 1111)\n",
      "Expected an audio onset event but got (352259, 1111)\n",
      "Expected an audio onset event but got (394194, 1111)\n",
      "Expected an audio onset event but got (426737, 1111)\n",
      "Expected an audio onset event but got (460552, 1111)\n",
      "Expected an audio onset event but got (485290, 1111)\n",
      "Expected an audio onset event but got (511043, 1111)\n",
      "Expected an audio onset event but got (538356, 1111)\n",
      "Expected an audio onset event but got (566933, 1111)\n",
      "Expected an audio onset event but got (594784, 1111)\n",
      "Expected an audio onset event but got (619761, 1111)\n",
      "Expected an audio onset event but got (645429, 1111)\n",
      "Expected an audio onset event but got (678381, 1111)\n",
      "Expected an audio onset event but got (711803, 1111)\n",
      "Expected an audio onset event but got (796980, 1111)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(<AudioType.LYRICAL: 0>, 25506.317, 25515.9797),\n",
       " (<AudioType.LYRICAL: 0>, 34498.317, 34507.9797),\n",
       " (<AudioType.LYRICAL: 0>, 50270, 50279.6627),\n",
       " (<AudioType.NON_LYRICAL: 2>, 54023.307, 54032.5423),\n",
       " (<AudioType.NON_LYRICAL: 2>, 62761.307, 62770.5423),\n",
       " (<AudioType.NON_LYRICAL: 2>, 78119, 78128.2353),\n",
       " (<AudioType.LYRICAL: 0>, 176551.632, 176564.9481),\n",
       " (<AudioType.LYRICAL: 0>, 186826.632, 186839.9481),\n",
       " (<AudioType.LYRICAL: 0>, 205695, 205708.3161),\n",
       " (<AudioType.LYRICAL: 0>, 209453.831, 209461.5011),\n",
       " (<AudioType.LYRICAL: 0>, 217080.831, 217088.5011),\n",
       " (<AudioType.LYRICAL: 0>, 230390, 230397.6701),\n",
       " (<AudioType.LYRICAL: 0>, 234156.988, 234168.6112),\n",
       " (<AudioType.LYRICAL: 0>, 244472.988, 244484.6112),\n",
       " (<AudioType.LYRICAL: 0>, 262969, 262980.6232),\n",
       " (<AudioType.NON_LYRICAL: 2>, 266740.995, 266749.3215),\n",
       " (<AudioType.NON_LYRICAL: 2>, 274676.995, 274685.3215),\n",
       " (<AudioType.NON_LYRICAL: 2>, 288813, 288821.3265),\n",
       " (<AudioType.NON_LYRICAL: 2>, 292559.182, 292575.18409999995),\n",
       " (<AudioType.NON_LYRICAL: 2>, 304732.182, 304748.18409999995),\n",
       " (<AudioType.NON_LYRICAL: 2>, 326757, 326773.0021),\n",
       " (<AudioType.NON_LYRICAL: 2>, 330480.365, 330487.23589999997),\n",
       " (<AudioType.NON_LYRICAL: 2>, 338417.365, 338424.23589999997),\n",
       " (<AudioType.NON_LYRICAL: 2>, 352415, 352421.8709),\n",
       " (<AudioType.NON_LYRICAL: 2>, 360216.182, 360232.18409999995),\n",
       " (<AudioType.NON_LYRICAL: 2>, 372332.182, 372348.18409999995),\n",
       " (<AudioType.NON_LYRICAL: 2>, 394359, 394375.0021),\n",
       " (<AudioType.LYRICAL: 0>, 398137.988, 398149.6112),\n",
       " (<AudioType.LYRICAL: 0>, 408407.988, 408419.6112),\n",
       " (<AudioType.LYRICAL: 0>, 426896, 426907.6232),\n",
       " (<AudioType.LYRICAL: 0>, 464489.831, 464497.5011),\n",
       " (<AudioType.LYRICAL: 0>, 472160.831, 472168.5011),\n",
       " (<AudioType.LYRICAL: 0>, 485458, 485465.6701),\n",
       " (<AudioType.NON_LYRICAL: 2>, 489227.995, 489236.3215),\n",
       " (<AudioType.NON_LYRICAL: 2>, 497112.995, 497121.3215),\n",
       " (<AudioType.NON_LYRICAL: 2>, 511223, 511231.3265),\n",
       " (<AudioType.LYRICAL: 0>, 542297.317, 542306.9797),\n",
       " (<AudioType.LYRICAL: 0>, 551298.317, 551307.9797),\n",
       " (<AudioType.LYRICAL: 0>, 567108, 567117.6627),\n",
       " (<AudioType.NON_LYRICAL: 2>, 570872.307, 570881.5423),\n",
       " (<AudioType.NON_LYRICAL: 2>, 579602.307, 579611.5423),\n",
       " (<AudioType.NON_LYRICAL: 2>, 594964, 594973.2353),\n",
       " (<AudioType.NON_LYRICAL: 2>, 623648.365, 623655.2359),\n",
       " (<AudioType.NON_LYRICAL: 2>, 631585.365, 631592.2359),\n",
       " (<AudioType.NON_LYRICAL: 2>, 645611, 645617.8709),\n",
       " (<AudioType.LYRICAL: 0>, 649373.632, 649386.9481),\n",
       " (<AudioType.LYRICAL: 0>, 659692.632, 659705.9481),\n",
       " (<AudioType.LYRICAL: 0>, 678550, 678563.3161),\n",
       " (<AudioType.NON_LYRICAL: 2>, 800880.182, 800896.1841000001),\n",
       " (<AudioType.NON_LYRICAL: 2>, 813051.182, 813067.1841000001)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_event_data_list(\"01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
